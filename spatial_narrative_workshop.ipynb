{"cells":[{"cell_type":"markdown","metadata":{"id":"aUojVOiIhoEv"},"source":["# Spatial Narratives Project"]},{"cell_type":"markdown","metadata":{"id":"iZ0kCbYUh4gu"},"source":["## **Task Description: Place name Extraction from Text**"]},{"cell_type":"markdown","metadata":{"id":"fcfL-sEdGCIm"},"source":["Assuming we know nothing about the geography of the place(s) described by the corpus, what can we learn about it. In particular:\n","* **What places are there?** These can be:\n"," * `Toponyms` (Keswick, Pooley Bridge, the River Lowther, etc)\n"," * `Geographical features` (the town, a hill, the road)\n"," * `‘Between’ places` (‘between A and B there are nice views of the lake’, ‘on the way to A we did something’)\n","* **What are those places like?** (ie how are they described)?\n","* **What events happened at those places?**\n","* **How are the places mentioned related to each other?**\n","* **What can we infer about places by bringing this information together**. For example:\n"," * If one text says ‘At Pooley Bridge we hired a boat to row on the lake’ and another says ‘Pooley Bridge is at the head of Ullswater’, can we infer that at Pooley Bridge you can hire boats to row on Ullswater.\n"," * If one text says that ‘On the road from Pooley Bridge to Penrith there is a bridge after three miles’ and another says that ‘The road from Pooley Bridge to Penrith crosses the River Lowther’ can we draw this together to the bridge after three miles is over the Lowther’\n","\n","To answer these I think that we need the following concepts:\n","1.\t**Regions**: Any type of place that exists but for which we may not know where it is or what its boundaries are. These are the building blocks for all types of places. Examples could include: Keswick, a lake, the road, the shore, etc.\n","2.\t**Attributes**: These give a region its sense of place. They may be:\n"," * features (‘the field has cattle in \n","it’)\n"," * events (‘we stayed the night in Keswick’)\n"," * descriptive terms (‘Ullswater is beautiful’)\n"," * people (‘on the road we met Mr Smith’)\n"," * others\n","3.\t**Connections**: These connect two or more regions. They may be:\n"," * explicit distances or directions (‘A is four miles from B’, ‘A is north of B’)\n"," * implicit distances or directions (‘A is at the head of B’, ‘A is near B’, ‘A is on the left of B’)\n"," * regions themselves (‘There is a road from A to B’ where ‘road’ is the connection)\n"," * events (‘we walked from A to B’)\n"," * non-spatial connections (‘A and B are lakes’, ‘A and B are beautiful’)\n"," * other and undefined (For example in chapter titles – ‘Grasmere and Ambleside’).\n"]},{"cell_type":"markdown","source":["# Rule-Based method\n","In this section, we will apply a rule-based approach that uses regular expression (regex) and a combination of other techniques to extract and visualize place names from text. "],"metadata":{"id":"8wf3pdzkWFS3"}},{"cell_type":"markdown","source":["## **Step 1: Downloading the workshop materials**\n","Let's download (clone) the resources for the workshop from the [Spatial Narrative Workshop](https://github.com/IgnatiusEzeani/spatial_narratives_workshop)  GitHub repository."],"metadata":{"id":"VQzZg_4jQ9Ch"}},{"cell_type":"code","source":["!git clone https://github.com/IgnatiusEzeani/spatial_narratives_workshop.git"],"metadata":{"id":"16hV3t2_K-Uj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675022046099,"user_tz":0,"elapsed":1131,"user":{"displayName":"Ignatius Ezeani","userId":"00944355542181313663"}},"outputId":"ecb6c9c8-6030-4871-bc4d-43bf6298374d"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'spatial_narratives_workshop'...\n","remote: Enumerating objects: 50, done.\u001b[K\n","remote: Counting objects: 100% (50/50), done.\u001b[K\n","remote: Compressing objects: 100% (45/45), done.\u001b[K\n","remote: Total 50 (delta 5), reused 45 (delta 3), pack-reused 0\u001b[K\n","Unpacking objects: 100% (50/50), 804.62 KiB | 2.93 MiB/s, done.\n"]}]},{"cell_type":"markdown","source":["The `spatial_narratives_workshop` directory contains an example file `example_text.txt`. Our aim is to read file and display the text as well as identify all the place names mentioned in the text.\n","\n","Let's change into the `spatial_narratives_workshop` directory."],"metadata":{"id":"-gHbsXiiSIGX"}},{"cell_type":"code","source":["cd spatial_narratives_workshop/"],"metadata":{"id":"cSzKcVhYR-1r","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675022049404,"user_tz":0,"elapsed":271,"user":{"displayName":"Ignatius Ezeani","userId":"00944355542181313663"}},"outputId":"e1e0ba5b-aa50-4f93-a116-f8d8f8177bd7"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/spatial_narratives_workshop\n"]}]},{"cell_type":"markdown","source":["Open the `example_text.txt` file and read its content into the variable `example_text`"],"metadata":{"id":"vLZdA28eViwc"}},{"cell_type":"code","source":["example_text =  open('example_text.txt').read()\n","print(example_text) #show the content of the file"],"metadata":{"id":"S4AuLs0uUti2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675022999305,"user_tz":0,"elapsed":284,"user":{"displayName":"Ignatius Ezeani","userId":"00944355542181313663"}},"outputId":"78539856-7774-40eb-f6ee-46b5235dbf75"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["From Penrith two roads lead to Pooley Bridge, about six miles distant, which spans the Eamont just at its issue from Ulleswater. Either road may be taken, be we recommend that which follows the Shap road to Eamont Bridge. Carleton Hall is near to it on the left. Cross the bridge, and take the first road to the right. At this point, on the left, are the druidical remains called King Arthur's Round Table, and Mayborough. Immediately after crossing Pooley Bridge, the road runs along the western shore of ULLESWATER.\n","\n","To Patterdale, a distance of ten miles; but, before proceeding along it, the tourist would do well to take a walk of a few miles along the eastern shore, in the direction of Martindale, from several points on which he will obtain a good view of the lake. Should this deviation be made, it will be necessary to return by the same road to Pooley Bridge, where there are two small inns, at which boats, for an excursion on the water, or for fishing, may be procured if desired. A fine view may be had from the top of Dunmallet, on which are the vestiges of a Roman fort. \n","\n","There is some good fishing here in the lake and stream. Trout, perch, and eels, are numerous, and large lake-trout are sometimes, though seldom, taken. Lowther Castle, the seat of the Earl of Lonsdale, is distant from this bridge about four miles. Ulleswater is nine miles in length, by nearly a mile wide, at the broadest point; but, owing to its irregular form, it is divided into three reaches, the first of which is closed in by Hallen Fell, on the western shore.\n"]}]},{"cell_type":"markdown","source":["## **Step 2: Extracting a placename**\n","Here we think about a way to extract a known place name (e.g. `Penrith`) from the text.\n","\n","We start by defining a funtion, `extract_placename`, that can help us identify and extract a given from a piece of text..."],"metadata":{"id":"LCQBR8lJTAii"}},{"cell_type":"code","source":["import re\n","def extract_placename(text, plname):\n","  p = re.compile(f'{plname}[\\.,\\s\\n]')\n","  iterator = p.finditer(text)\n","  for match in iterator:\n","    print(match.span())"],"metadata":{"id":"-w51uoIkdtdI","executionInfo":{"status":"ok","timestamp":1675022060530,"user_tz":0,"elapsed":235,"user":{"displayName":"Ignatius Ezeani","userId":"00944355542181313663"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["placename = 'Penrith'\n","extract_placename(example_text, placename)"],"metadata":{"id":"HQ4dmJwUgoyw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675022234076,"user_tz":0,"elapsed":253,"user":{"displayName":"Ignatius Ezeani","userId":"00944355542181313663"}},"outputId":"a2725e8f-f22d-4a6b-ee17-270357a7a251"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["(5, 13)\n"]}]},{"cell_type":"markdown","source":["The output `(5, 13)` above indicates that there is one occurence of 'Penrith' in the text and it occurs between character positions `5` and `13`. By the way the first character is in position `0` (not `1`)."],"metadata":{"id":"O07te8A0ehBC"}},{"cell_type":"markdown","source":["### **Task1 :**\n","\n","*By calling the above function (`extract_placename`) on the text in `example_text`. Write the code to extract mentions of `Pooley Bridge`, `Eamont`, `Eamont Bridge` and `Lowther Castle` and discuss your observations.*"],"metadata":{"id":"NfgZhaHDh8cG"}},{"cell_type":"markdown","source":["## **Step 3: Extracting with a list of placenames**\n","As can be observed above, we often need to extract multiple names from the text in one run. For example, we may want to to identify and extract all the place names in the list `['Penrith', 'Pooley Bridge', 'Eamont', 'Eamont Bridge']`.\n","\n","Let's rename our function `extract_placenames()` and modify it to be able to identify multiple place names from a list. We will display each place name along with its instance in text."],"metadata":{"id":"izKuNqBFhE8e"}},{"cell_type":"code","source":["def extract_placename(text, plnames):\n","  for name in plnames:\n","    p = re.compile(f'{name.lower()}[\\.,\\s\\n]')\n","    iterator = p.finditer(text.lower())\n","    for match in iterator:\n","      print(match.span(), name)\n","\n","place_names = ['Penrith', 'Pooley Bridge', 'Eamont', 'Eamont Bridge']\n","extract_placename(example_text, place_names)"],"metadata":{"id":"xSZOnPpDsyQs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675023536936,"user_tz":0,"elapsed":262,"user":{"displayName":"Ignatius Ezeani","userId":"00944355542181313663"}},"outputId":"613c3d1f-4013-4af5-8a31-5d4fc3b38e20"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["(5, 13) Penrith\n","(31, 45) Pooley Bridge\n","(450, 464) Pooley Bridge\n","(856, 870) Pooley Bridge\n","(87, 94) Eamont\n","(207, 214) Eamont\n","(207, 221) Eamont Bridge\n"]}]},{"cell_type":"markdown","source":["We now have now have multiple place names extracted from the text based on the list we have. However, we still have a little problem. How do we extract '`Eamont`' and '`Eamont Bridge`' as two separate places?\n","\n","We will try to tackle this by:\n","\n","1.   Sorting the list of names in reverse order of the lenght of names. That way `Eamont Bridge` will come before `Eamont`. \n","2.   Ensuring that no two placenames are extracted with the same start index. So when we extract `Eamont Bridge` with the start index of `207` as above, we will not extract `Eamont` again with the same start index. So we need to keep track of the start index.\n","\n","Okay, let's modify the function and code...\n"],"metadata":{"id":"YWC5lhpLu_EA"}},{"cell_type":"code","source":["# Re-defining the functions \n","def extract_placenames(text, plnames):\n","  extracted_place_names={} # dictionary to keep track of extracted name instances\n","  for name in plnames:\n","    p = re.compile(f'{name}[\\.,\\s\\n]')\n","    iterator = p.finditer(text)\n","    for match in iterator:\n","      start, end = match.span()\n","\n","      # also the place name is expected to be at least three characters in length \n","      if end-start>=3 and start not in extracted_place_names:\n","        extracted_place_names[start] = text[start:end][:-1]\n","  return extracted_place_names\n","\n","place_names = ['Penrith', 'Pooley Bridge', 'Eamont', 'Eamont Bridge']\n","\n","# sort the place names: ['Eamont Bridge', 'Pooley Bridge', 'Penrith', 'Eamont']\n","place_names = sorted(place_names, key=lambda x: len(x), reverse=True)\n","\n","extracted_place_names = extract_placenames(example_text, place_names)\n","extracted_place_names"],"metadata":{"id":"O6SljcviwW02","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675024909276,"user_tz":0,"elapsed":273,"user":{"displayName":"Ignatius Ezeani","userId":"00944355542181313663"}},"outputId":"999bba3d-44bf-4523-f8e2-afecd2973fdb"},"execution_count":68,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{31: 'Pooley Bridge',\n"," 450: 'Pooley Bridge',\n"," 856: 'Pooley Bridge',\n"," 207: 'Eamont Bridge',\n"," 5: 'Penrith',\n"," 87: 'Eamont'}"]},"metadata":{},"execution_count":68}]},{"cell_type":"markdown","source":["It will be good to sort the dictionary in the ascending order of start indexes to keep track of everything for visualization."],"metadata":{"id":"bvYNEWUS-v5l"}},{"cell_type":"code","source":["extracted_place_names = extract_placenames(example_text, place_names)\n","extracted_place_names = {i:extracted_place_names[i] for i in sorted(extracted_place_names)}\n","extracted_place_names"],"metadata":{"id":"RzBvp3yh-wwV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675024350043,"user_tz":0,"elapsed":261,"user":{"displayName":"Ignatius Ezeani","userId":"00944355542181313663"}},"outputId":"1bfbdfcb-e480-4c8d-9eb9-9e19a6f89d2a"},"execution_count":55,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{5: 'Penrith',\n"," 31: 'Pooley Bridge,',\n"," 87: 'Eamont',\n"," 207: 'Eamont Bridge.',\n"," 450: 'Pooley Bridge,',\n"," 522: 'Patterdale,',\n"," 856: 'Pooley Bridge,'}"]},"metadata":{},"execution_count":55}]},{"cell_type":"markdown","source":["## **Step 4: Visualizing the outputs**\n","It is often a good idea to present a graphic representation of our outputs for better visualization and understanding of how our process works.\n","\n","So let's define functions that displays a visualisation of the text and the extracted place names in HTML format."],"metadata":{"id":"mu3VPj2cqYid"}},{"cell_type":"markdown","source":["#### **Visualizing the plain text**"],"metadata":{"id":"-eKIFfzsaXRH"}},{"cell_type":"code","source":["import IPython\n","\n","def show_text(txtstr):\n","  start_mark = f'<mark class=\"entity\" style=\"background: #FFFFFF; line-height: 2; border-radius: 0.35em;\">'\n","  end_mark = '\\n</mark>'\n","  return IPython.display.HTML(f\"{start_mark}{txtstr}{end_mark}\")\n","\n","show_text(example_text)"],"metadata":{"id":"fw3i7Od_sH1c","colab":{"base_uri":"https://localhost:8080/","height":353},"executionInfo":{"status":"ok","timestamp":1675024109949,"user_tz":0,"elapsed":220,"user":{"displayName":"Ignatius Ezeani","userId":"00944355542181313663"}},"outputId":"f668f18d-c7ad-40fa-d978-800adf9ec51a"},"execution_count":46,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<mark class=\"entity\" style=\"background: #FFFFFF; line-height: 2; border-radius: 0.35em;\">From Penrith two roads lead to Pooley Bridge, about six miles distant, which spans the Eamont just at its issue from Ulleswater. Either road may be taken, be we recommend that which follows the Shap road to Eamont Bridge. Carleton Hall is near to it on the left. Cross the bridge, and take the first road to the right. At this point, on the left, are the druidical remains called King Arthur's Round Table, and Mayborough. Immediately after crossing Pooley Bridge, the road runs along the western shore of ULLESWATER.\n","\n","To Patterdale, a distance of ten miles; but, before proceeding along it, the tourist would do well to take a walk of a few miles along the eastern shore, in the direction of Martindale, from several points on which he will obtain a good view of the lake. Should this deviation be made, it will be necessary to return by the same road to Pooley Bridge, where there are two small inns, at which boats, for an excursion on the water, or for fishing, may be procured if desired. A fine view may be had from the top of Dunmallet, on which are the vestiges of a Roman fort. \n","\n","There is some good fishing here in the lake and stream. Trout, perch, and eels, are numerous, and large lake-trout are sometimes, though seldom, taken. Lowther Castle, the seat of the Earl of Lonsdale, is distant from this bridge about four miles. Ulleswater is nine miles in length, by nearly a mile wide, at the broadest point; but, owing to its irregular form, it is divided into three reaches, the first of which is closed in by Hallen Fell, on the western shore.\n","</mark>"]},"metadata":{},"execution_count":46}]},{"cell_type":"markdown","source":["#### **Visualizing the extracted place names**\n","Having extracted the place names, we can also define functions that can 'mark-up' or highlight the extracted place names from the plain text so we can visualize it in HTML format.\n","\n","Let's call the first function `get_tagged_list()`. It will parse the text with dictionary of extracted place names and identify spans that will be tagged as place names in the text. Its output is a list of tuples containing text spans and tags (either `PL-NAME` or `None`)"],"metadata":{"id":"tgbwfPbh4TWD"}},{"cell_type":"code","source":["# extract all known place name in a list\n","def get_tagged_list(text, ext_pl_names):\n","  begin, tokens_tags = 0, []\n","  for start, plname in ext_pl_names.items():\n","    length, ent, tag = len(plname), plname, 'PL-NAME'\n","    if begin <= start:\n","      tokens_tags.append((text[begin:start], None))\n","      tokens_tags.append((text[start:start+length], tag))\n","      begin = start+length\n","  tokens_tags.append((text[begin:], None)) #add the last untagged chunk\n","  return tokens_tags\n","\n","get_tagged_list(example_text, extracted_place_names)"],"metadata":{"id":"Wb0VTn717w7B","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675024131090,"user_tz":0,"elapsed":240,"user":{"displayName":"Ignatius Ezeani","userId":"00944355542181313663"}},"outputId":"6be727c5-a647-4ddb-d4d1-ad555ace65b4"},"execution_count":47,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('From Penrith two roads le', None),\n"," ('ad to Poole', 'PL-NAME'),\n"," ('y Bridge, about', None),\n"," (' six miles', 'PL-NAME'),\n"," (\" distant, which spans the Eamont just at its issue from Ulleswater. Either road may be taken, be we recommend that which follows the Shap road to Eamont Bridge. Carleton Hall is near to it on the left. Cross the bridge, and take the first road to the right. At this point, on the left, are the druidical remains called King Arthur's Round Table, and Mayborough. Immediately after crossing Pooley Bridge, the road runs along the western shore of ULLESWATER.\\n\\nTo Patterdale, a distance of ten miles; but, before proceeding along it, the tourist would do well to take a walk of a few miles along the eastern shore, in the direction of Martindale, from several points on which he will obtain a good view of the lake. Should this deviation be made, it will be necessary to return by the same road to Pooley Bridge, where there are two small inns, at which boats, for an excursion on the water, or for fishing, may be procured if desired. A fine view may be had from the top of Dunmallet, on which are the vestiges of a Roman fort. \\n\\nThere is some good fishing here in the lake and stream. Trout, perch, and eels, are numerous, and large lake-trout are sometimes, though seldom, taken. Lowther Castle, the seat of the Earl of Lonsdale, is distant from this bridge about four miles. Ulleswater is nine miles in length, by nearly a mile wide, at the broadest point; but, owing to its irregular form, it is divided into three reaches, the first of which is closed in by Hallen Fell, on the western shore.\",\n","  None)]"]},"metadata":{},"execution_count":47}]},{"cell_type":"markdown","source":["The second function `mark_up`, which takes a `token` (actually a span of characters) and a tag (i.e. `PL-NAME` for place name) basically marks up or highlights any piece of text with a given background colour in HTML format."],"metadata":{"id":"MOHEigcrFvFo"}},{"cell_type":"code","source":["# format a typical entity for display \n","def mark_up(token, tag):\n","  if tag:\n","    start_mark = f'<mark class=\"entity\" style=\"background: #feca74 ; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">'\n","    end_mark = '\\n</mark>'\n","    start_span = '<span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">'\n","    end_span = '\\n</span>'\n","    return f\"\\n{start_mark}{token}{start_span}{tag}{end_span}{end_mark}\"\n","  return f\"{token}\"\n","\n","IPython.display.HTML(mark_up('Penrith', 'PL-NAME'))"],"metadata":{"id":"Lt2UoFAdHE8D","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1675024157131,"user_tz":0,"elapsed":236,"user":{"displayName":"Ignatius Ezeani","userId":"00944355542181313663"}},"outputId":"ff43c580-0b32-4881-b561-c4c2803c257a"},"execution_count":48,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","<mark class=\"entity\" style=\"background: #feca74 ; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">Penrith<span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PL-NAME\n","</span>\n","</mark>"]},"metadata":{},"execution_count":48}]},{"cell_type":"markdown","source":["Finally, we piece everything together with the function `generate_html()` which does exactly that by marking up the output of the `get_tagged_list()` with the `mark_up()` function."],"metadata":{"id":"glVyOK7IIoxp"}},{"cell_type":"code","source":["# generate html formatted text \n","def generate_html(token_tag_list):\n","  start_div = f'<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">'\n","  end_div = '\\n</div>'\n","  html = start_div\n","  for token, tag in token_tag_list:\n","    html += mark_up(token,tag)\n","  html += end_div\n","  return html"],"metadata":{"id":"UWpp-0NoFvrQ","executionInfo":{"status":"ok","timestamp":1675024159728,"user_tz":0,"elapsed":200,"user":{"displayName":"Ignatius Ezeani","userId":"00944355542181313663"}}},"execution_count":49,"outputs":[]},{"cell_type":"code","source":["tag_list = get_tagged_list(example_text, extracted_place_names) \n","IPython.display.HTML(generate_html(tag_list))"],"metadata":{"id":"3QoDHlRg9bNK","colab":{"base_uri":"https://localhost:8080/","height":492},"executionInfo":{"status":"ok","timestamp":1675024371828,"user_tz":0,"elapsed":247,"user":{"displayName":"Ignatius Ezeani","userId":"00944355542181313663"}},"outputId":"af32600e-1670-4017-fab7-a4759a066d9d"},"execution_count":56,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">From \n","<mark class=\"entity\" style=\"background: #feca74 ; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">Penrith<span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PL-NAME\n","</span>\n","</mark> two roads lead to \n","<mark class=\"entity\" style=\"background: #feca74 ; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">Pooley Bridge,<span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PL-NAME\n","</span>\n","</mark> about six miles distant, which spans the \n","<mark class=\"entity\" style=\"background: #feca74 ; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">Eamont<span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PL-NAME\n","</span>\n","</mark> just at its issue from Ulleswater. Either road may be taken, be we recommend that which follows the Shap road to \n","<mark class=\"entity\" style=\"background: #feca74 ; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">Eamont Bridge.<span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PL-NAME\n","</span>\n","</mark> Carleton Hall is near to it on the left. Cross the bridge, and take the first road to the right. At this point, on the left, are the druidical remains called King Arthur's Round Table, and Mayborough. Immediately after crossing \n","<mark class=\"entity\" style=\"background: #feca74 ; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">Pooley Bridge,<span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PL-NAME\n","</span>\n","</mark> the road runs along the western shore of ULLESWATER.\n","\n","To \n","<mark class=\"entity\" style=\"background: #feca74 ; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">Patterdale,<span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PL-NAME\n","</span>\n","</mark> a distance of ten miles; but, before proceeding along it, the tourist would do well to take a walk of a few miles along the eastern shore, in the direction of Martindale, from several points on which he will obtain a good view of the lake. Should this deviation be made, it will be necessary to return by the same road to \n","<mark class=\"entity\" style=\"background: #feca74 ; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">Pooley Bridge,<span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PL-NAME\n","</span>\n","</mark> where there are two small inns, at which boats, for an excursion on the water, or for fishing, may be procured if desired. A fine view may be had from the top of Dunmallet, on which are the vestiges of a Roman fort. \n","\n","There is some good fishing here in the lake and stream. Trout, perch, and eels, are numerous, and large lake-trout are sometimes, though seldom, taken. Lowther Castle, the seat of the Earl of Lonsdale, is distant from this bridge about four miles. Ulleswater is nine miles in length, by nearly a mile wide, at the broadest point; but, owing to its irregular form, it is divided into three reaches, the first of which is closed in by Hallen Fell, on the western shore.\n","</div>"]},"metadata":{},"execution_count":56}]},{"cell_type":"markdown","source":["## **Step 5: Extracting with a gazetteer list**\n","Our previous examples so far is only able to extract and visualise a few place names. Obviously, for a chance to be able to extract all the place names in the text, we will need a more comprehensive list. \n","\n","So for this task, we will apply the techniques defined above with a list of the Lake District place names from the gazetteer created by [Source]() to identify and extract mentions of the place names in the same text."],"metadata":{"id":"3_g1_U1Cn_u4"}},{"cell_type":"code","source":["place_names = [name.strip() for name in open('placenames.txt').readlines()]\n","# place_names"],"metadata":{"id":"orzBT4Yhg9R6","executionInfo":{"status":"ok","timestamp":1675024396070,"user_tz":0,"elapsed":301,"user":{"displayName":"Ignatius Ezeani","userId":"00944355542181313663"}}},"execution_count":57,"outputs":[]},{"cell_type":"markdown","source":["Let's modify the `extract_place_name()` function to sort the input list in the reverse order of lengths of names automatically and also return a version of the created dictionary sorted in ascending order of the index."],"metadata":{"id":"CYUW-Zq-87-T"}},{"cell_type":"code","source":["# Re-defining the functions \n","def extract_placenames(text, plnames):\n","  #sort the list in reverse order...\n","  plnames = sorted(plnames, key=lambda x: len(x), reverse=True)\n","  extracted_place_names = {} # dictionary to keep track of extracted name instances\n","  for name in plnames:\n","    p = re.compile(f'{name}[\\.,\\s\\n]')\n","    iterator = p.finditer(text)\n","    for match in iterator:\n","      start, end = match.span()\n","\n","      # also the place name is expected to be at least three characters in length \n","      if end-start>=3 and start not in extracted_place_names:\n","        extracted_place_names[start] = text[start:end][:-1]\n","  return {i:extracted_place_names[i] for i in sorted(extracted_place_names)}\n","\n","extracted_place_names = extract_placenames(example_text, place_names)\n","extracted_place_names"],"metadata":{"id":"ojuKuGKu8ycW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675024807418,"user_tz":0,"elapsed":587,"user":{"displayName":"Ignatius Ezeani","userId":"00944355542181313663"}},"outputId":"fb2621a7-d039-4ff1-d555-edb90bf17f98"},"execution_count":64,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{5: 'Penrith',\n"," 31: 'Pooley Bridge',\n"," 117: 'Ulleswater',\n"," 194: 'Shap',\n"," 207: 'Eamont Bridge',\n"," 222: 'Carleton Hall',\n"," 394: 'Round Table',\n"," 450: 'Pooley Bridge',\n"," 506: 'ULLESWATER',\n"," 522: 'Patterdale',\n"," 693: 'Martindale',\n"," 856: 'Pooley Bridge',\n"," 1033: 'Dunmallet',\n"," 1241: 'Lowther Castle',\n"," 1281: 'Lonsdale',\n"," 1337: 'Ulleswater',\n"," 1522: 'Hallen Fell'}"]},"metadata":{},"execution_count":64}]},{"cell_type":"markdown","source":["Then let's visualize..."],"metadata":{"id":"3MQFc7LGER2e"}},{"cell_type":"code","source":["tag_list = get_tagged_list(example_text, extracted_place_names) \n","IPython.display.HTML(generate_html(tag_list))"],"metadata":{"id":"H8QelSDhDROp","colab":{"base_uri":"https://localhost:8080/","height":507},"executionInfo":{"status":"ok","timestamp":1675024824385,"user_tz":0,"elapsed":248,"user":{"displayName":"Ignatius Ezeani","userId":"00944355542181313663"}},"outputId":"81a662e1-bfff-48ef-a37c-2f67e2066e9b"},"execution_count":65,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">From \n","<mark class=\"entity\" style=\"background: #feca74 ; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">Penrith<span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PL-NAME\n","</span>\n","</mark> two roads lead to \n","<mark class=\"entity\" style=\"background: #feca74 ; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">Pooley Bridge<span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PL-NAME\n","</span>\n","</mark>, about six miles distant, which spans the Eamont just at its issue from \n","<mark class=\"entity\" style=\"background: #feca74 ; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">Ulleswater<span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PL-NAME\n","</span>\n","</mark>. Either road may be taken, be we recommend that which follows the \n","<mark class=\"entity\" style=\"background: #feca74 ; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">Shap<span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PL-NAME\n","</span>\n","</mark> road to \n","<mark class=\"entity\" style=\"background: #feca74 ; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">Eamont Bridge<span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PL-NAME\n","</span>\n","</mark>. \n","<mark class=\"entity\" style=\"background: #feca74 ; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">Carleton Hall<span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PL-NAME\n","</span>\n","</mark> is near to it on the left. Cross the bridge, and take the first road to the right. At this point, on the left, are the druidical remains called King Arthur's \n","<mark class=\"entity\" style=\"background: #feca74 ; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">Round Table<span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PL-NAME\n","</span>\n","</mark>, and Mayborough. Immediately after crossing \n","<mark class=\"entity\" style=\"background: #feca74 ; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">Pooley Bridge<span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PL-NAME\n","</span>\n","</mark>, the road runs along the western shore of \n","<mark class=\"entity\" style=\"background: #feca74 ; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">ULLESWATER<span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PL-NAME\n","</span>\n","</mark>.\n","\n","To \n","<mark class=\"entity\" style=\"background: #feca74 ; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">Patterdale<span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PL-NAME\n","</span>\n","</mark>, a distance of ten miles; but, before proceeding along it, the tourist would do well to take a walk of a few miles along the eastern shore, in the direction of \n","<mark class=\"entity\" style=\"background: #feca74 ; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">Martindale<span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PL-NAME\n","</span>\n","</mark>, from several points on which he will obtain a good view of the lake. Should this deviation be made, it will be necessary to return by the same road to \n","<mark class=\"entity\" style=\"background: #feca74 ; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">Pooley Bridge<span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PL-NAME\n","</span>\n","</mark>, where there are two small inns, at which boats, for an excursion on the water, or for fishing, may be procured if desired. A fine view may be had from the top of \n","<mark class=\"entity\" style=\"background: #feca74 ; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">Dunmallet<span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PL-NAME\n","</span>\n","</mark>, on which are the vestiges of a Roman fort. \n","\n","There is some good fishing here in the lake and stream. Trout, perch, and eels, are numerous, and large lake-trout are sometimes, though seldom, taken. \n","<mark class=\"entity\" style=\"background: #feca74 ; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">Lowther Castle<span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PL-NAME\n","</span>\n","</mark>, the seat of the Earl of \n","<mark class=\"entity\" style=\"background: #feca74 ; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">Lonsdale<span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PL-NAME\n","</span>\n","</mark>, is distant from this bridge about four miles. \n","<mark class=\"entity\" style=\"background: #feca74 ; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">Ulleswater<span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PL-NAME\n","</span>\n","</mark> is nine miles in length, by nearly a mile wide, at the broadest point; but, owing to its irregular form, it is divided into three reaches, the first of which is closed in by \n","<mark class=\"entity\" style=\"background: #feca74 ; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">Hallen Fell<span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PL-NAME\n","</span>\n","</mark>, on the western shore.\n","</div>"]},"metadata":{},"execution_count":65}]},{"cell_type":"markdown","source":["As you may have observed from the output above, some of the place names where missed by this method either because they were not found in the gazetteer list (e.g. `Eamont`, `Earl of Lonsdale`) or inconsistent capitalization (e.g. `Patterdale` vs `PATTERDALE`) or even spelling errors.\n","\n","We will attempt to address these issues in the next section using the named entity recognizer."],"metadata":{"id":"MIJDeIj5w4eh"}},{"cell_type":"markdown","source":["## **Step 6: Extracting geographical feature nouns with list**\n","To extract geographical features from a list of feature nouns (e.g. `castle`, `ridge`, `forest`, `village`, `river` etc), we will apply the same method.\n","\n","To enable us apply a new tag `GEO-NOUN`, let's modify the `get_tagged_list()` function to  default to the `PLNAME` tag while supporting other tags.\n"],"metadata":{"id":"b4RGgDoawe91"}},{"cell_type":"code","source":["# extract all known place name in a list\n","def get_tagged_list(text, ext_pl_names, tag='PL-NAME'): #incl the tag parameter \n","  begin, tokens_tags = 0, []\n","  for start, plname in ext_pl_names.items():\n","    length, ent, tag = len(plname), plname, tag\n","    if begin <= start:\n","      tokens_tags.append((text[begin:start], None))\n","      tokens_tags.append((text[start:start+length], tag))\n","      begin = start+length\n","  tokens_tags.append((text[begin:], None)) #add the last untagged chunk\n","  return tokens_tags"],"metadata":{"id":"pE7PMYXM2K6c","executionInfo":{"status":"ok","timestamp":1675025643007,"user_tz":0,"elapsed":377,"user":{"displayName":"Ignatius Ezeani","userId":"00944355542181313663"}}},"execution_count":86,"outputs":[]},{"cell_type":"markdown","source":["To reuse the `extract_placenames()` function, let's rename and modify the function to be more generic"],"metadata":{"id":"_Rb2yzb96cca"}},{"cell_type":"code","source":["# Rename 'placename' to 'entities' \n","def extract_entities(text, ent_list):\n","  ent_list = sorted(ent_list, key=lambda x: len(x), reverse=True)\n","  extracted_entities = {} # dictionary to keep track of extracted name instances\n","  for name in ent_list:\n","    p = re.compile(f' {name}[\\.,\\s\\n]')\n","    iterator = p.finditer(text)\n","    for match in iterator:\n","      start, end = match.span()\n","\n","      # also the place name is expected to be at least three characters in length \n","      if end-start>=3 and start not in extracted_place_names:\n","        extracted_entities[start] = text[start:end][:-1]\n","  return {i:extracted_entities[i] for i in sorted(extracted_entities)}"],"metadata":{"id":"iU6RXojK6bIS","executionInfo":{"status":"ok","timestamp":1675026459180,"user_tz":0,"elapsed":220,"user":{"displayName":"Ignatius Ezeani","userId":"00944355542181313663"}}},"execution_count":101,"outputs":[]},{"cell_type":"code","source":["geonouns = [geonoun.strip() for geonoun in open('geo_feature_nouns.txt').readlines()]\n","# geonouns"],"metadata":{"id":"deCyn8BZ57Sx","executionInfo":{"status":"ok","timestamp":1675025649243,"user_tz":0,"elapsed":241,"user":{"displayName":"Ignatius Ezeani","userId":"00944355542181313663"}}},"execution_count":88,"outputs":[]},{"cell_type":"code","source":["BG_COLOR = {\n","    'GPE':'#feca74', 'CARDINAL':'#e4e7d2', 'FAC':'#9cc9cc','QUANTITY':'#e4e7d2',\n","    'PERSON':'#aa9cfc', 'ORDINAL':'#e4e7d2', 'ORG':'#7aecec', 'PL-NAME':'#feca74',\n","    'no_tag':'#FFFFFF','GEO-NOUN': '#9cc9cc', 'NORP':'#d9fe74', 'LOC':'#9ac9f5',\n","    'DATE':'#c7f5a9', 'PRODUCT':'#edf5a9', 'EVENT': '#e1a9f5','TIME':'#a9f5bc',\n","    'WORK_OF_ART':'#e6c1d7', 'LAW':'#e6e6c1','LANGUAGE':'#c9bdc7', \n","    'PERCENT':'#c9ebf5', 'MONEY':'#b3d6f2','EMOTION':'#f2ecd0',\n","    'TIME-sem':'#d0e0f2', 'MOVEMENT':'#f2d0d0'\n","}"],"metadata":{"id":"FfrXgHLQUg7x","executionInfo":{"status":"ok","timestamp":1675025878244,"user_tz":0,"elapsed":231,"user":{"displayName":"Ignatius Ezeani","userId":"00944355542181313663"}}},"execution_count":94,"outputs":[]},{"cell_type":"code","source":["tagged_geonouns = get_tagged_list(example_text, extract_entities(example_text, geonouns), 'GEO-NOUN')\n","IPython.display.HTML(generate_html(tagged_geonouns))"],"metadata":{"id":"kw8m_Jm28USg","colab":{"base_uri":"https://localhost:8080/","height":527},"executionInfo":{"status":"ok","timestamp":1675026466867,"user_tz":0,"elapsed":319,"user":{"displayName":"Ignatius Ezeani","userId":"00944355542181313663"}},"outputId":"0cd52fd1-293f-4cea-dfd9-38e9f7b3c832"},"execution_count":102,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">From Penrith two roads lead to Pooley Bridge, about six miles distant, which spans the Eamont just at its issue from Ulleswater. Either\n","<mark class=\"entity\" style=\"background: #9cc9cc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\"> road<span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GEO-NOUN\n","</span>\n","</mark> may be taken, be we recommend that which follows the Shap\n","<mark class=\"entity\" style=\"background: #9cc9cc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\"> road<span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GEO-NOUN\n","</span>\n","</mark> to Eamont Bridge. Carleton Hall is near to it on the left. Cross the\n","<mark class=\"entity\" style=\"background: #9cc9cc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\"> bridge<span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GEO-NOUN\n","</span>\n","</mark>, and take the first\n","<mark class=\"entity\" style=\"background: #9cc9cc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\"> road<span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GEO-NOUN\n","</span>\n","</mark> to the right. At this\n","<mark class=\"entity\" style=\"background: #9cc9cc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\"> point<span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GEO-NOUN\n","</span>\n","</mark>, on the left, are the druidical remains called King Arthur's Round Table, and Mayborough. Immediately after crossing Pooley Bridge, the\n","<mark class=\"entity\" style=\"background: #9cc9cc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\"> road<span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GEO-NOUN\n","</span>\n","</mark> runs along the western\n","<mark class=\"entity\" style=\"background: #9cc9cc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\"> shore<span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GEO-NOUN\n","</span>\n","</mark> of ULLESWATER.\n","\n","To Patterdale, a distance of ten miles; but, before proceeding along it, the tourist would do well to take a walk of a few miles along the eastern\n","<mark class=\"entity\" style=\"background: #9cc9cc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\"> shore<span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GEO-NOUN\n","</span>\n","</mark>, in the direction of Martindale, from several points on which he will obtain a good view of the\n","<mark class=\"entity\" style=\"background: #9cc9cc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\"> lake<span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GEO-NOUN\n","</span>\n","</mark>. Should this deviation be made, it will be necessary to return by the same\n","<mark class=\"entity\" style=\"background: #9cc9cc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\"> road<span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GEO-NOUN\n","</span>\n","</mark> to Pooley Bridge, where there are two small inns, at which boats, for an excursion on the\n","<mark class=\"entity\" style=\"background: #9cc9cc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\"> water<span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GEO-NOUN\n","</span>\n","</mark>, or for fishing, may be procured if desired. A fine view may be had from the\n","<mark class=\"entity\" style=\"background: #9cc9cc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\"> top<span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GEO-NOUN\n","</span>\n","</mark> of Dunmallet, on which are the vestiges of a Roman fort. \n","\n","There is some good fishing here in the\n","<mark class=\"entity\" style=\"background: #9cc9cc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\"> lake<span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GEO-NOUN\n","</span>\n","</mark> and\n","<mark class=\"entity\" style=\"background: #9cc9cc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\"> stream<span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GEO-NOUN\n","</span>\n","</mark>. Trout, perch, and eels, are numerous, and large lake-trout are sometimes, though seldom, taken. Lowther Castle, the\n","<mark class=\"entity\" style=\"background: #9cc9cc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\"> seat<span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GEO-NOUN\n","</span>\n","</mark> of the Earl of Lonsdale, is distant from this\n","<mark class=\"entity\" style=\"background: #9cc9cc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\"> bridge<span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GEO-NOUN\n","</span>\n","</mark> about four miles. Ulleswater is nine miles in length, by nearly a mile wide, at the broadest point; but, owing to its irregular form, it is divided into three reaches, the first of which is closed in by Hallen Fell, on the western\n","<mark class=\"entity\" style=\"background: #9cc9cc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\"> shore<span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GEO-NOUN\n","</span>\n","</mark>.\n","</div>"]},"metadata":{},"execution_count":102}]},{"cell_type":"code","source":["!pip install lemminflect"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"muru-HtcUA9p","executionInfo":{"status":"ok","timestamp":1675025743479,"user_tz":0,"elapsed":3803,"user":{"displayName":"Ignatius Ezeani","userId":"00944355542181313663"}},"outputId":"059b1f04-42b4-4d47-c382-a04fd947035e"},"execution_count":92,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: lemminflect in /usr/local/lib/python3.8/dist-packages (0.2.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from lemminflect) (1.21.6)\n"]}]},{"cell_type":"code","source":["# Expand list with inflections and lemmas\n","from lemminflect import getLemma, getInflection\n","def get_inflections(names_list):\n","    gf_names_inflected = []\n","    for w in names_list:\n","      gf_names_inflected.append(w)\n","      gf_names_inflected.extend(list(getInflection(w.strip(), tag='NNS', inflect_oov=False)))\n","      gf_names_inflected.extend(list(getLemma(w.strip(), 'NOUN', lemmatize_oov=False)))\n","    return list(set(gf_names_inflected))\n","\n","get_inflections(geonouns)\n","\n","# tag_list = get_tagged_list(example_text, extracted_place_names) "],"metadata":{"id":"Ed_C2M8W5LfE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tagged_geonouns = get_tagged_list(example_text, extract_entities(example_text, geonouns), 'GEO-NOUN')\n","IPython.display.HTML(generate_html(tagged_geonouns))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":472},"id":"tNaFjsodTejm","executionInfo":{"status":"ok","timestamp":1675025913035,"user_tz":0,"elapsed":239,"user":{"displayName":"Ignatius Ezeani","userId":"00944355542181313663"}},"outputId":"373a3b20-92fe-48eb-c1f6-5c2275bac0ce"},"execution_count":97,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">From Penrith two roads lead to Pooley Bridge, about six miles distant, which spans the Eamont just at its issue from Ulleswater. Either road may be taken, be we recommend that which follows the Shap road to Eamont Bridge. Carleton Hall is near to it on the left. Cross the bridge, and take the first road to the right. At this point, on the left, are the druidical remains called King Arthur's Round Table, and Mayborough. Immediately after crossing Pooley Bridge, the road runs along the western shore of ULLESWATER.\n","\n","To Patterdale, a distance of ten miles; but, before proceeding along it, the tourist would do well to take a walk of a few miles along the eastern\n","<mark class=\"entity\" style=\"background: #9cc9cc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\"> shore,<span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GEO-NOUN\n","</span>\n","</mark> in the direction of Martindale, from several points on which he will obtain a good view of the\n","<mark class=\"entity\" style=\"background: #9cc9cc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\"> lake.<span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GEO-NOUN\n","</span>\n","</mark> Should this deviation be made, it will be necessary to return by the same road to Pooley Bridge, where there are two small inns, at which boats, for an excursion on the water, or for fishing, may be procured if desired. A fine view may be had from the top of Dunmallet, on which are the vestiges of a Roman fort. \n","\n","There is some good fishing here in the lake and\n","<mark class=\"entity\" style=\"background: #9cc9cc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\"> stream.<span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GEO-NOUN\n","</span>\n","</mark> Trout, perch, and eels, are numerous, and large lake-trout are sometimes, though seldom, taken. Lowther Castle, the seat of the Earl of Lonsdale, is distant from this bridge about four miles. Ulleswater is nine miles in length, by nearly a mile wide, at the broadest point; but, owing to its irregular form, it is divided into three reaches, the first of which is closed in by Hallen Fell, on the western shore.\n","</div>"]},"metadata":{},"execution_count":97}]},{"cell_type":"markdown","source":["# Using a Named Entity Recognizer\n","With the rule-based approach, we could extract the place names in our list. However, it is limited in a number of ways.\n","* It requires an exhaustive list of place names which is difficult to build for different types of writings.\n","* Hand-crafted rules for all possible scenarios will need to be developed\n","  - e.g. spelling errors, capitalizations, inflections etc.\n","  - Over-lapping instances ('Eamont' vs 'Eamont Bridge')\n","* It will be more difficult to extract references to time and date\n","* The approach will not generalize well with other corpora \n","\n"],"metadata":{"id":"fV08iUDFXbnS"}},{"cell_type":"markdown","source":["## **Step 6: Using a Named Entity Recognizer**\n","Our previous examples so far is only able to extract and visualise a few place names. Obviously, for a chance to be able to extract all the place names in the text, we will need a more comprehensive list. "],"metadata":{"id":"tianIoMBT814"}},{"cell_type":"code","source":["EXAMPLE_TEXT = open('gold_standard/Anon_cqp_66.xml').read()\n","\n","# EXAMPLE_TEXT = open(os.path.join('data','example_texts','Anon1857_b.txt')).read()\n","\n","place_names = [name.strip() for name in open('placenames.txt').readlines()]\n","# geof_names  = open('data/geo_feature_nouns.txt').readlines()\n","\n","# Expand list with inflections and lemmas\n","def get_inflections(names_list):\n","    gf_names_inflected = []\n","    for w in names_list:\n","      gf_names_inflected.append(w)\n","      gf_names_inflected.extend(list(getInflection(w.strip(), tag='NNS', inflect_oov=False)))\n","      gf_names_inflected.extend(list(getLemma(w.strip(), 'NOUN', lemmatize_oov=False)))\n","    return list(set(gf_names_inflected))\n","\n","# Get the index list of a sem tag\n","def get_sem_tagged(tag_type):\n","  index_list = []\n","  for i in range(len(output_doc)):\n","    if output_doc[i]._.pymusas_tags[0].startswith(tag_type[0]):\n","       index_list.append(i)\n","  return index_list\n","\n","# extract all `seen` entities from a list of place names \n","def extract_entities_with_regex(txtstr, ent_list, tag='PL-NAME'):\n","  entityPosLen={}\n","  for ent in ent_list:\n","    p = re.compile(f'{ent}[\\.,\\s\\n]')#, flags=re.IGNORECASE)\n","    iterator = p.finditer(txtstr)\n","    for match in iterator:\n","      start, end = match.span()\n","      if end-start>=3 and start not in entityPosLen:\n","        entityPosLen[start] = (end-start, txtstr[start:end], tag)\n","  return entityPosLen\n","\n","# extract all known entities with spacy\n","def extract_entities_with_spacy(spacy_doc):\n","  entityPosLen={}\n","  for ent in spacy_doc.ents:\n","    entityPosLen[ent.start_char] = (len(ent.text), ent.text, ent.label_)\n","  return entityPosLen\n","\n","# extract all entities with semtagger\n","def extract_entities_with_semtagger(tokens, index_list, tag):\n","  entityPosLen={}\n","  for i in index_list:\n","    start_char = 1+len(\" \".join(tokens[:i]))\n","    entityPosLen[start_char] = (len(tokens[i]), tokens[i], tag)\n","  return entityPosLen\n","\n","# extract all known entities in a lists\n","def get_token_tags(txtstr, entities):\n","  begin, tokens_tags = 0, []\n","  for start, vals in entities.items():\n","    length, ent, tag = vals\n","    if begin <= start:\n","      tokens_tags.append((txtstr[begin:start], None))\n","      tokens_tags.append((txtstr[start:start+length], tag))\n","      begin = start+length\n","  tokens_tags.append((txtstr[begin:], None)) #add the last untagged chunk\n","  return tokens_tags\n","\n","BG_COLOR = {'GPE':'#feca74', 'CARDINAL':'#e4e7d2', 'FAC':'#9cc9cc',\n","            'QUANTITY':'#e4e7d2', 'PERSON':'#aa9cfc', 'ORDINAL':'#e4e7d2', \n","            'ORG':'#7aecec', 'PL-NAME':'#feca74', 'no_tag':'#FFFFFF',\n","            'GEO-FEATURE': '#9cc9cc', 'NORP':'#d9fe74', 'LOC':'#9ac9f5',\n","            'DATE':'#c7f5a9', 'PRODUCT':'#edf5a9', 'EVENT': '#e1a9f5',\n","            'TIME':'#a9f5bc', 'WORK_OF_ART':'#e6c1d7', 'LAW':'#e6e6c1',\n","            'LANGUAGE':'#c9bdc7', 'PERCENT':'#c9ebf5', 'MONEY':'#b3d6f2',\n","            'EMOTION':'#f2ecd0', 'TIME-sem':'#d0e0f2', 'MOVEMENT':'#f2d0d0'\n","}\n","\n","# format a typical entity for display \n","def format_entity(token, tag):\n","  if tag:\n","    start_mark = f'<mark class=\"entity\" style=\"background: {BG_COLOR[tag]}; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">'\n","    end_mark = '\\n</mark>'\n","    start_span = '<span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">'\n","    end_span = '\\n</span>'\n","    return f\"\\n{start_mark}{token}{start_span}{tag}{end_span}{end_mark}\"\n","  return f\"{token}\"\n","\n","# format a typical entity span for display \n","def format_span(ent_span, tag):\n","  new_ent_span = ent_span.copy()\n","  if tag:\n","    start_mark = f'<mark class=\"entity\" style=\"background: {BG_COLOR[tag]}; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">'\n","    end_mark = '\\n</mark>'\n","    start_span = '<span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">'\n","    end_span = '\\n</span>'  \n","    if len(new_ent_span)>1:\n","      new_ent_span[0] = f\"\\n{start_mark}{ent_span[0]}\"\n","      new_ent_span[-1] = f\"{ent_span[-1]}{start_span}{tag}{end_span}{end_mark}\"\n","      return new_ent_span\n","    else:\n","      new_ent_span[0] = f\"\\n{start_mark}{ent_span[0]}{start_span}{tag}{end_span}{end_mark}\"\n","      return new_ent_span\n","  return new_ent_span\n","\n","# generate html formatted text \n","def generate_html(token_tag_list):\n","  start_div = f'<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">'\n","  end_div = '\\n</div>'\n","  html = start_div\n","  for token, tag in token_tag_list:\n","    html += format_entity(token,tag)\n","  html += end_div\n","  return html\n","\n","# show text unformated text\n","def show_text(txtstr):\n","  start_mark = f'<mark class=\"entity\" style=\"background: #FFFFFF; line-height: 2; border-radius: 0.35em;\">'\n","  end_mark = '\\n</mark>'\n","  return IPython.display.HTML(f\"{start_mark}{txtstr}{end_mark}\")"],"metadata":{"id":"OcFadxf9MK4b","executionInfo":{"status":"ok","timestamp":1675025308593,"user_tz":0,"elapsed":244,"user":{"displayName":"Ignatius Ezeani","userId":"00944355542181313663"}}},"execution_count":77,"outputs":[]},{"cell_type":"markdown","source":["### **Building the NLP Pipeline**\n"],"metadata":{"id":"uQtKvdZT_KD_"}},{"cell_type":"markdown","metadata":{"id":"PAuHgOW_GJdB"},"source":["\n","We start by building a baseline NER tagger. Two approaches are considered:\n","1. Try an existing Named Entity Recognition (NER) tool - **`SpaCy`**\n","2. Build a Rule-based recogniser for all known regions\n","3. Annotate our corpus with required tags and train a statistical model for name and feature recognition"]},{"cell_type":"markdown","metadata":{"id":"jOdjjJwFHv11"},"source":["#### Clone the Lake Distric Corpus directory"]},{"cell_type":"code","source":["!git clone https://github.com/UCREL/LakeDistrictCorpus.git"],"metadata":{"id":"Jl6-820B1lGy"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F3YnapT0EY7w"},"outputs":[],"source":["cd LakeDistrictCorpus/"]},{"cell_type":"markdown","metadata":{"id":"vb8f7aoPsYgL"},"source":["#### Install Spacy and PyMUSAS Models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LAlcRE91v4N1"},"outputs":[],"source":["!pip uninstall spacy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VlYyPzJrHswb"},"outputs":[],"source":["!pip install spacy==3.3.1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dZdQ0GiFHZM5"},"outputs":[],"source":["!python -m spacy download en_core_web_sm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AYV4adpwEmjg"},"outputs":[],"source":["!pip install https://github.com/UCREL/pymusas-models/releases/download/en_dual_none_contextual-0.3.1/en_dual_none_contextual-0.3.1-py3-none-any.whl"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nIEhMdMw6MRU"},"outputs":[],"source":["!pip3 install lemminflect"]},{"cell_type":"markdown","metadata":{"id":"jlyjC3b7s1SK"},"source":["#### Importing all necessary modules"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bFcH2wJ2tjlc"},"outputs":[],"source":["# importing all necessary modules\n","import os\n","import sys\n","import re\n","import spacy\n","import pandas as pd\n","import IPython\n","import matplotlib.pyplot as plt\n","import en_core_web_sm\n","import collections\n","from collections import Counter\n","from lemminflect import getLemma, getInflection\n","from wordcloud import WordCloud, STOPWORDS"]},{"cell_type":"code","source":[],"metadata":{"id":"09OKaFuAMRDj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"s16_0fHjMQ_S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"FAATMoKqMQ8E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ycM0mtDdMQ4m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"11yUCooqMQ1V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"1tlU-APlMQx-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"hQwoTj59MQuW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"gFITy5SYMQrF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"f-DyHLirMQnv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"sMq3k8g0MQkT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"bwcjud9-MQga"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"WwZjw-rYMQcf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Lzl0hp6yMQZM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Z-KyqkXZMQUv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"1FE9duCbMQQb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"lKwfzsUKMQKV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"_7HGldCiMQGd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"8DqoDNRgMQCo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"QBfl-14xMP_F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"bWAqxq7_MP68"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"xWn6w9n0MP3s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","from bs4 import BeautifulSoup\n","from collections import Counter\n","\n","for fname in os.listdir('gold_standard'):\n","  with open(os.path.join('gold_standard',fname), 'r') as f:\n","\t  data = f.read()\n","  bs_data = BeautifulSoup(data, \"xml\")\n","  pl_names_found = [str(pl)[9:-10] for pl in  bs_data.find_all('cdplace')]\n","  print(fname, len(pl_names_found))"],"metadata":{"id":"A5OzZkAiGR8Y","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675026570338,"user_tz":0,"elapsed":1622,"user":{"displayName":"Ignatius Ezeani","userId":"00944355542181313663"}},"outputId":"edc4b17a-3e9c-40e5-a0f8-df4b23478563"},"execution_count":104,"outputs":[{"output_type":"stream","name":"stdout","text":["Wordsworth_cqp_47.xml 117\n","Smith_cqp_5.xml 37\n","Defoe_cqp_4.xml 119\n","Keats_cqp_44.xml 0\n","Cockin_cqp_19.xml 0\n","Young_cqp_11.xml 124\n","Rutland_cqp_42.xml 48\n","Anon_cqp_66.xml 569\n","West_cqp_17.xml 1305\n","Pennant_cqp_15.xml 302\n","Gray_cqp_13.xml 181\n","Smith_cqp_6.xml 37\n","Wesley_cqp_9.xml 35\n","Garnett_cqp_62.xml 0\n","Wakefield_cqp_37.xml 120\n","Shaw_cqp_24.xml 185\n","Pennant_cqp_12.xml 49\n","Ruskin_cqp_55.xml 232\n","Otley__cqp_49.xml 1931\n","Wordsworth_cqp_58.xml 397\n","Sullivan_cqp_20.xml 80\n","Lt.Hammond._cqp_2.xml 62\n","Coleridge_cqp_33.xml 261\n","Brown_cqp_10.xml 16\n","Rix_cqp_78.xml 67\n","Phillips_cqp_38.xml 42\n","Smith_cqp_7.xml 112\n","Clarke_cqp_63.xml 56\n"]}]},{"cell_type":"code","source":["from bs4 import BeautifulSoup\n","from collections import Counter\n","\n","# Reading the data inside the xml\n","# file to a variable under the name\n","# data\n","\n","with open('/content/LakeDistrictCorpus/gold_standard/Brown_cqp_10.xml', 'r') as f:\n","\tdata = f.read()\n","\n","# Passing the stored data inside\n","# the beautifulsoup parser, storing\n","# the returned object\n","Bs_data = BeautifulSoup(data, \"xml\")\n","\n","# Finding all instances of tag\n","# `unique`\n","pl_names_found = Bs_data.find_all('cdplace')\n","pl_names_found = [str(pl)[9:-10] for pl in pl_names_found]\n","print(pl_names_found)\n","len(pl_names_found), Counter(pl_names_found).most_common()\n","\n","# # ------------------\n","# wordcloud = WordCloud(width = 800, height = 800,\n","#         background_color ='white',\n","#         min_font_size = 10).generate(' '.join(pl_names_found))\n","\n","# # plot the WordCloud image\t\t\t\t\t\n","# plt.figure(figsize = (7, 7), facecolor = None)\n","# plt.imshow(wordcloud)\n","# plt.axis(\"off\")\n","# plt.tight_layout(pad = 0)\n","\n","\n","# # Using find() to extract attributes\n","# # of the first instance of the tag\n","# b_name = Bs_data.find('child', {'name':'Frank'})\n","\n","# print(b_name)\n","\n","# # Extracting the data stored in a\n","# # specific attribute of the\n","# # `child` tag\n","# value = b_name.get('test')\n","\n","# print(value)\n"],"metadata":{"id":"fq3LkhMYBHal"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vTGykomH2HN7"},"source":["#### Define functions and load data"]},{"cell_type":"code","source":["!wget https://raw.githubusercontent.com/SpaceTimeNarratives/demo_app/main/code/data/placenames.txt"],"metadata":{"id":"52t5f6197G9f"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dw-9gazeNa4l"},"outputs":[],"source":["EXAMPLE_TEXT = open('/content/LakeDistrictCorpus/gold_standard/Anon_cqp_66.xml').read()\n","\n","# EXAMPLE_TEXT = open(os.path.join('data','example_texts','Anon1857_b.txt')).read()\n","\n","place_names = [name.strip() for name in open('placenames.txt').readlines()]\n","# geof_names  = open('data/geo_feature_nouns.txt').readlines()\n","\n","# Expand list with inflections and lemmas\n","def get_inflections(names_list):\n","    gf_names_inflected = []\n","    for w in names_list:\n","      gf_names_inflected.append(w)\n","      gf_names_inflected.extend(list(getInflection(w.strip(), tag='NNS', inflect_oov=False)))\n","      gf_names_inflected.extend(list(getLemma(w.strip(), 'NOUN', lemmatize_oov=False)))\n","    return list(set(gf_names_inflected))\n","\n","# Get the index list of a sem tag\n","def get_sem_tagged(tag_type):\n","  index_list = []\n","  for i in range(len(output_doc)):\n","    if output_doc[i]._.pymusas_tags[0].startswith(tag_type[0]):\n","       index_list.append(i)\n","  return index_list\n","\n","# extract all `seen` entities from a list of place names \n","def extract_entities_with_regex(txtstr, ent_list, tag='PL-NAME'):\n","  entityPosLen={}\n","  for ent in ent_list:\n","    p = re.compile(f'{ent}[\\.,\\s\\n]')#, flags=re.IGNORECASE)\n","    iterator = p.finditer(txtstr)\n","    for match in iterator:\n","      start, end = match.span()\n","      if end-start>=3 and start not in entityPosLen:\n","        entityPosLen[start] = (end-start, txtstr[start:end], tag)\n","  return entityPosLen\n","\n","# extract all known entities with spacy\n","def extract_entities_with_spacy(spacy_doc):\n","  entityPosLen={}\n","  for ent in spacy_doc.ents:\n","    entityPosLen[ent.start_char] = (len(ent.text), ent.text, ent.label_)\n","  return entityPosLen\n","\n","# extract all entities with semtagger\n","def extract_entities_with_semtagger(tokens, index_list, tag):\n","  entityPosLen={}\n","  for i in index_list:\n","    start_char = 1+len(\" \".join(tokens[:i]))\n","    entityPosLen[start_char] = (len(tokens[i]), tokens[i], tag)\n","  return entityPosLen\n","\n","# extract all known entities in a lists\n","def get_token_tags(txtstr, entities):\n","  begin, tokens_tags = 0, []\n","  for start, vals in entities.items():\n","    length, ent, tag = vals\n","    if begin <= start:\n","      tokens_tags.append((txtstr[begin:start], None))\n","      tokens_tags.append((txtstr[start:start+length], tag))\n","      begin = start+length\n","  tokens_tags.append((txtstr[begin:], None)) #add the last untagged chunk\n","  return tokens_tags\n","\n","BG_COLOR = {'GPE':'#feca74', 'CARDINAL':'#e4e7d2', 'FAC':'#9cc9cc',\n","            'QUANTITY':'#e4e7d2', 'PERSON':'#aa9cfc', 'ORDINAL':'#e4e7d2', \n","            'ORG':'#7aecec', 'PL-NAME':'#feca74', 'no_tag':'#FFFFFF',\n","            'GEO-FEATURE': '#9cc9cc', 'NORP':'#d9fe74', 'LOC':'#9ac9f5',\n","            'DATE':'#c7f5a9', 'PRODUCT':'#edf5a9', 'EVENT': '#e1a9f5',\n","            'TIME':'#a9f5bc', 'WORK_OF_ART':'#e6c1d7', 'LAW':'#e6e6c1',\n","            'LANGUAGE':'#c9bdc7', 'PERCENT':'#c9ebf5', 'MONEY':'#b3d6f2',\n","            'EMOTION':'#f2ecd0', 'TIME-sem':'#d0e0f2', 'MOVEMENT':'#f2d0d0'\n","}\n","\n","# format a typical entity for display \n","def format_entity(token, tag):\n","  if tag:\n","    start_mark = f'<mark class=\"entity\" style=\"background: {BG_COLOR[tag]}; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">'\n","    end_mark = '\\n</mark>'\n","    start_span = '<span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">'\n","    end_span = '\\n</span>'\n","    return f\"\\n{start_mark}{token}{start_span}{tag}{end_span}{end_mark}\"\n","  return f\"{token}\"\n","\n","# format a typical entity span for display \n","def format_span(ent_span, tag):\n","  new_ent_span = ent_span.copy()\n","  if tag:\n","    start_mark = f'<mark class=\"entity\" style=\"background: {BG_COLOR[tag]}; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">'\n","    end_mark = '\\n</mark>'\n","    start_span = '<span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">'\n","    end_span = '\\n</span>'  \n","    if len(new_ent_span)>1:\n","      new_ent_span[0] = f\"\\n{start_mark}{ent_span[0]}\"\n","      new_ent_span[-1] = f\"{ent_span[-1]}{start_span}{tag}{end_span}{end_mark}\"\n","      return new_ent_span\n","    else:\n","      new_ent_span[0] = f\"\\n{start_mark}{ent_span[0]}{start_span}{tag}{end_span}{end_mark}\"\n","      return new_ent_span\n","  return new_ent_span\n","\n","# generate html formatted text \n","def generate_html(token_tag_list):\n","  start_div = f'<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">'\n","  end_div = '\\n</div>'\n","  html = start_div\n","  for token, tag in token_tag_list:\n","    html += format_entity(token,tag)\n","  html += end_div\n","  return html\n","\n","# show text unformated text\n","def show_text(txtstr):\n","  start_mark = f'<mark class=\"entity\" style=\"background: #FFFFFF; line-height: 2; border-radius: 0.35em;\">'\n","  end_mark = '\\n</mark>'\n","  return IPython.display.HTML(f\"{start_mark}{txtstr}{end_mark}\")"]},{"cell_type":"markdown","metadata":{"id":"bgHhZlUA20l5"},"source":["#### Add sem tagger to `spaCy` pipeline and process text"]},{"cell_type":"code","source":["# We exclude the following components as we do not need them. \n","nlp = spacy.load('en_core_web_sm')\n","# Load the English PyMUSAS rule based tagger in a separate spaCy pipeline\n","english_tagger_pipeline = spacy.load('en_dual_none_contextual')\n","# Adds the English PyMUSAS rule based tagger to the main spaCy pipeline\n","nlp.add_pipe('pymusas_rule_based_tagger', source=english_tagger_pipeline)"],"metadata":{"id":"3-lU_XzN_usK"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4nCHH22WIgex"},"outputs":[],"source":["# EXAMPLE_TEXT = open('data/example_texts/example_text.txt').read()\n","output_doc = nlp(EXAMPLE_TEXT)\n","\n","# print(f'Text\\tLemma\\tPOS\\tUSAS Tags')\n","# for i, token in enumerate(output_doc):\n","#     print(f'{token.text}\\t{token.lemma_}\\t{token.pos_}\\t{token._.pymusas_tags}')"]},{"cell_type":"markdown","metadata":{"id":"kcWZ_eqy-tGZ"},"source":["#### Define functions and the `Extractor` class"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eUAzirJuSbI9"},"outputs":[],"source":["import os\n","import re\n","from IPython.display import HTML\n","from collections import Counter\n","\n","nlp = spacy.load('en_core_web_sm')\n","\n","BG_COLOR = {'GPE':'#feca74', 'CARDINAL':'#e4e7d2', 'FAC':'#9cc9cc', 'QUANTITY':'#e4e7d2', 'PERSON':'#aa9cfc', 'ORDINAL':'#e4e7d2', 'ORG':'#7aecec',\n","            'PL-NAME':'#feca74', 'no_tag':'#FFFFFF', 'GEO-NOUN': '#9cc9cc', 'NORP':'#d9fe74', 'LOC':'#9ac9f5', 'DATE':'#c7f5a9', 'PRODUCT':'#edf5a9', \n","            'EVENT': '#e1a9f5', 'TIME':'#a9f5bc', 'WORK_OF_ART':'#e6c1d7', 'LAW':'#e6e6c1', 'LANGUAGE':'#c9bdc7', 'PERCENT':'#c9ebf5', 'MONEY':'#b3d6f2', \n","            'EMOTION':'#f2ecd0', 'TIME-sem':'#d0e0f2', 'MOVEMENT':'#f2d0d0', 'SP-PREP': '#f7d7e9', 'LOC-ADV': '#c4e5f5'\n","}\n","\n","# format a typical entity for display \n","def format_entity(token, tag):\n","  if tag:\n","    start_mark = f'<mark class=\"entity\" style=\"background: {BG_COLOR[tag]}; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">'\n","    end_mark = '\\n</mark>'\n","    start_span = '<span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">'\n","    end_span = '\\n</span>'\n","    return f\"\\n{start_mark}{token}{start_span}{tag}{end_span}{end_mark}\"\n","  return f\"{token}\"\n","\n","# extract all known entities in a lists\n","def get_token_tags(txtstr, entities):\n","  begin, tokens_tags = 0, []\n","  for start, vals in entities.items():\n","    length, ent, tag = vals\n","    if begin <= start:\n","      tokens_tags.append((txtstr[begin:start], None))\n","      tokens_tags.append((txtstr[start:start+length], tag))\n","      begin = start+length\n","  tokens_tags.append((txtstr[begin:], None)) #add the last untagged chunk\n","  return tokens_tags\n","\n","# Expand list with inflections and lemmas\n","def get_inflections(names_list):\n","    gf_names_inflected = []\n","    for w in names_list:\n","      w = w.strip()\n","      gf_names_inflected.append(w)\n","      gf_names_inflected.extend(list(getInflection(w.strip(), tag='NNS', inflect_oov=False)))\n","      gf_names_inflected.extend(list(getLemma(w.strip(), 'NOUN', lemmatize_oov=False)))\n","    return list(set(gf_names_inflected))\n","\n","combine = lambda x, y: (x[0], x[1]+' '+y[1], x[2])\n","\n","def combine_multi_tokens(a_list):\n","  new_list = [a_list.pop()]\n","  while a_list:\n","    last = a_list.pop()\n","    if new_list[-1][0] - last[0] == 1:\n","      new_list.append(combine(last, new_list.pop()))\n","    else:\n","      new_list.append(last)\n","  return sorted(new_list)\n","\n","# merge two entities\n","def merge_entities(first_ents, second_ents):\n","  return collections.OrderedDict(\n","      sorted({** second_ents, **first_ents}.items()))\n","# ------------------------------------------------------------------------------\n","# EXAMPLE_TEXT = open('data/example_texts/Anon1857_b.txt').read()\n","\n","EXAMPLE_TEXT = open('/content/LakeDistrictCorpus/gold_standard/Anon_cqp_66.xml').read()\n","place_names_tags = [(name.strip(), 'PL-NAME') for name in open('placenames.txt').readlines()]\n","# geof_nouns_tags = [(noun.strip(), 'GEO-NOUN') for noun in get_inflections(open('data/example_texts/geo_feature_nouns.txt').readlines())]\n","# spatial_preps_tags = [(prep.strip(), 'SP-PREP') for prep in open('data/example_texts/spatial_prepositions.txt').readlines()]\n","# locative_adverbs = [(advb[:25].strip(), 'LOC-ADV') for advb in open('data/example_texts/locativeAdverbs.txt').readlines()]\n","  \n","entity_tag_list = place_names_tags # + geof_nouns_tags + spatial_preps_tags + locative_adverbs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PwkNfLh8g8lk"},"outputs":[],"source":["class Extractor:\n","  def __init__(self, text, entity_tag_list):\n","    self.text = text\n","    self.tokens, self.tokenized_text, self.nlp_doc = self.process_text()\n","    self.entity_tag_list = entity_tag_list\n","    self.entities = self.extract_placenames()\n","    self.ner_entities = self.extract_ner_entities()\n","    self.sem_tag_types = ['EMOTION', 'MOVEMENT', 'TIME-sem']\n","    self.sem_entities = self.extract_sem_entities()\n","    \n","  def process_text(self):\n","      doc = nlp(self.text)\n","      tokens = [token.text for token in doc]\n","      tokenized_text = \" \".join(tokens)\n","      nlp_doc = nlp(tokenized_text)\n","      return tokens, tokenized_text, nlp_doc\n","\n","  def extract_placenames(self):\n","    entities = {}\n","    for ent, tag in self.entity_tag_list:\n","      p = re.compile(f'{ent}[\\.,\\s\\n]')#, flags=re.IGNORECASE)\n","      iterator = p.finditer(self.tokenized_text)\n","      for match in iterator:\n","        start, end = match.span()\n","        if end-start>=2 and start not in entities:\n","          entities[start] = (end-start, self.tokenized_text[start:end-1], tag)\n","    return collections.OrderedDict(sorted(entities.items()))\n","\n","  def extract_ner_entities(self):\n","    entities = {}\n","    for ent in self.nlp_doc.ents:\n","      tag='PL-NAME' if ent.label_ in ['GPE', 'ORG', 'FAC'] else ent.label_\n","      entities[ent.start_char] = (len(ent.text), ent.text, tag)\n","    return collections.OrderedDict(sorted(entities.items()))\n","\n","  def extract_sem_entities(self):\n","    entities = {}\n","    for tag_type in self.sem_tag_types:\n","      tag_indices = [(i, token.text, tag_type) for i, token in enumerate(self.nlp_doc) if token._.pymusas_tags[0].startswith(tag_type[0])]\n","      if tag_indices:\n","        for i, token, tag in combine_multi_tokens(tag_indices):\n","          start_char = 1+len(\" \".join(self.tokens[:i]))\n","          entities[start_char] = (len(token), token, tag)\n","    return collections.OrderedDict(sorted(entities.items()))\n","\n","  # generate html formatted text \n","  def visualize(self, ents=None, include_ner=True, include_sem=True):\n","    html, end_div = f'<div class=\"entities\" style=\"line-height: 2.3; direction: ltr\">', '\\n</div>'\n","    if ents:\n","      entities = ents\n","    else:\n","      if include_ner:\n","        entities =  merge_entities(self.entities, self.ner_entities)\n","      if include_sem:\n","        entities = merge_entities(self.entities, self.sem_entities)\n","      if include_ner and include_sem:\n","        entities = merge_entities(self.entities, merge_entities(self.ner_entities, self.sem_entities))\n","    for token, tag in get_token_tags(self.tokenized_text, entities):\n","      html += format_entity(token,tag)\n","    html += end_div\n","    return HTML(html)"]},{"cell_type":"markdown","metadata":{"id":"CDxwHd1z_CW1"},"source":["#### Instantiating the `extractor` and Visualising entities "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uQoCCOiUAAHi"},"outputs":[],"source":["extractor = Extractor(EXAMPLE_TEXT,entity_tag_list)\n","my_ents = {i:(l, e, t) for i, (l, e, t) in extractor.entities.items() if t in ['PL-NAME']}\n","extractor.visualize(my_ents)"]},{"cell_type":"markdown","metadata":{"id":"vBPN4g5R-P0B"},"source":["### **Regex Tagging**\n","#### Using Regex-based tagger for `place_names` and `geographical feature nouns`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JzKJOK2BzUlM"},"outputs":[],"source":["place_names = sorted(place_names, key=lambda x: len(x), reverse=True)\n","\n","#extract place name entities/mentions\n","pl_names_ents = extract_entities_with_regex(EXAMPLE_TEXT, place_names, tag='PL-NAME')\n","\n","# #extract geo feature entities/mentions\n","# gf_names_ents = extract_entities_with_regex(EXAMPLE_TEXT, get_inflections(geof_names), tag='GEO-FEATURE')\n","\n","# # Merge all extracted fearture names and mentions\n","# regex_entities = {**pl_names_ents, **gf_names_ents}\n","# regex_entities = collections.OrderedDict(sorted(regex_entities.items()))\n","\n","IPython.display.HTML(\n","    generate_html(get_token_tags(EXAMPLE_TEXT, pl_names_ents)))"]},{"cell_type":"markdown","metadata":{"id":"VM57tYlXlO2Y"},"source":["### **`spaCy` NER model**\n","##### Tag text with standard NER tags: `LOC`, `PERSON`, `ORG`, `DATE-TIME` etc"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OriP7rQeB0xC"},"outputs":[],"source":["spacy_entities = extract_entities_with_spacy(output_doc)\n","\n","IPython.display.HTML(\n","    generate_html(get_token_tags(text, spacy_entities)))"]},{"cell_type":"markdown","metadata":{"id":"Zw9jVk97R4SB"},"source":["### **Regex + `spaCy` tagger**\n","Combining the Regex + Spacy tagger"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wb5ein1zR2sF"},"outputs":[],"source":["regex_spacy_entities = regex_entities.copy()\n","\n","# Do not overwrite regex with spacy entities\n","banned_start_points=[]\n","for start, (length, e, t) in regex_spacy_entities.items():\n","  banned_start_points.extend(list(range(start, start+length-1)))\n","\n","# Add only entities not captured by regex\n","for start, (l, e, t) in spacy_entities.items():\n","  if start not in banned_start_points:\n","    if t in ['GPE','ORG', 'LOC', 'FAC']:#, 'PERSON']:\n","      regex_spacy_entities[start] = (l, e, 'PL-NAME')\n","    else:\n","      regex_spacy_entities[start] = (l, e, t)\n","regex_spacy_entities = collections.OrderedDict(sorted(regex_spacy_entities.items()))\n","\n","IPython.display.HTML(\n","    generate_html(get_token_tags(text, regex_spacy_entities)))"]},{"cell_type":"markdown","metadata":{"id":"1tCywxkPi1r2"},"source":["# Update: Adding the Semantic Tagger\n","\n","\n","1. The demo app is now available on the project Github space and hopefully everyone can still access it\n","  - Demo App link: https://spacetimenarratives.streamlit.app/ \n","\n"]},{"cell_type":"markdown","metadata":{"id":"WuQcL3dOE4Of"},"source":["### **Semantic Tagging**\n","##### Tag text with `MOVEMENT`, `TIME` and `EMOTION` semantic tags"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q-3eFRcpT9iL"},"outputs":[],"source":["tag_types = ['EMOTION', 'MOVEMENT', 'TIME-sem']\n","semtagger_entities={}\n","for tag_type in tag_types:\n","  tag_entities = extract_entities_with_semtagger(text_tokens, get_sem_tagged(tag_type),tag_type) \n","  semtagger_entities = {**semtagger_entities, **tag_entities}\n","semtagger_entities = collections.OrderedDict(sorted(semtagger_entities.items()))\n","\n","IPython.display.HTML(\n","    generate_html(get_token_tags(text, semtagger_entities)))"]},{"cell_type":"markdown","metadata":{"id":"u2cVItnJdPNS"},"source":["#### 4. Regex + **`spaCy`** + semantic tagger"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8LMebUmnw7br"},"outputs":[],"source":["regex_spacy_sem_entities = regex_spacy_entities.copy()\n","\n","# Do not overwrite regex entities\n","banned_start_points=[]\n","for start, (length, e, t) in regex_spacy_sem_entities.items():\n","  banned_start_points.extend(list(range(start, start+length-1)))\n","\n","# Add only entities not captured by regex\n","for start, (l, e, t) in semtagger_entities.items():\n","  if start not in banned_start_points:\n","      regex_spacy_sem_entities[start] = (l, e, t)\n","\n","regex_spacy_sem_entities = collections.OrderedDict(sorted(regex_spacy_sem_entities.items()))\n","\n","IPython.display.HTML(generate_html(get_token_tags(text, regex_spacy_sem_entities)))"]},{"cell_type":"markdown","metadata":{"id":"WwolMngoq_hs"},"source":["# Annotation Tools"]},{"cell_type":"markdown","metadata":{"id":"s-orEl9cYw2H"},"source":["\n","Data Annotation: \n","\n","1. Lighttag: https://www.lighttag.io/\n","2. AI-Annotator: https://ioannotator.com/\n","3. Prodigy: https://prodi.gy/\n","4. Tagtog: https://www.tagtog.com/\n","5. Brat Annotation Tool: https://brat.nlplab.org/index.html"]},{"cell_type":"markdown","metadata":{"id":"_D2v7-Vdlcux"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"VidjHyKVHA3W"},"source":["# Google Map API"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8DNVD4k3C3fg"},"outputs":[],"source":["pip install -U googlemaps"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KVmeOyWuF244"},"outputs":[],"source":["pip install geopandas"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0uIw5KufCmEe"},"outputs":[],"source":["API_KEY = 'AIzaSyCK0vBr87V6T6xFqktA7jttfD0k8AsX1fY'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s3TYJTsFCv6O"},"outputs":[],"source":["import googlemaps\n","# from datetime import datetime"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NDAhyYa6G_qS"},"outputs":[],"source":["gmaps = googlemaps.Client(key=API_KEY)\n","\n","# Geocoding an address\n","geocode_result1 = gmaps.geocode('Penrith, Lake district ')\n","geocode_result2 = gmaps.geocode('Pooley Bridge, Lake district')\n","print(geocode_result1[0])\n","print(geocode_result2[0])\n","\n","# Look up an address with reverse geocoding\n","# reverse_geocode_result = gmaps.reverse_geocode((40.714224, -73.961452))\n","reverse_geocode_result = gmaps.reverse_geocode((54.6786628, -2.7247091))\n","\n","pl1 = geocode_result1[0]['address_components'][0]['long_name'] #, reverse_geocode_result\n","pl2 = geocode_result2[0]['address_components'][0]['long_name'] #, reverse_geocode_result\n","\n","pl1, pl2\n","# Request directions via public transit\n","# now = datetime.now()\n","# directions_result = gmaps.directions(\"Sydney Town Hall\", \n","#                                      \"Parramatta, NSW\",\n","#                                      mode=\"transit\",\n","#                                      departure_time=now)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j7VG-C_ZZ9xB"},"outputs":[],"source":["pd.DataFrame(geocode_result1[0]['geometry'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-b2VIR9Zaqb7"},"outputs":[],"source":["pd.DataFrame(geocode_result2[0]['geometry'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vgdZRlb4DCce"},"outputs":[],"source":["# Requires cities name\n","dist = gmaps.distance_matrix(pl1, pl2)['rows'][0]['elements'][0]\n","  \n","# Printing the result\n","print(dist)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"28WnKznuwZNz"},"outputs":[],"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","from shapely.geometry import Point\n","import geopandas as gpd\n","from geopandas import GeoDataFrame\n","\n","df = pd.read_csv(\"Long_Lats.csv\", delimiter=',', skiprows=0, low_memory=False)\n","\n","geometry = [Point(xy) for xy in zip(df['Longitude'], df['Latitude'])]\n","gdf = GeoDataFrame(df, geometry=geometry)   \n","\n","#this is a simple map that goes with geopandas\n","world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n","gdf.plot(ax=world.plot(figsize=(10, 6)), marker='o', color='red', markersize=15);"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4tw8O5gRxCou"},"outputs":[],"source":["df = pd.DataFrame(\n","    {'City': ['Buenos Aires', 'Brasilia', 'Santiago', 'Bogota', 'Caracas'],\n","     'Country': ['Argentina', 'Brazil', 'Chile', 'Colombia', 'Venezuela'],\n","     'Latitude': [-34.58, -15.78, -33.45, 4.60, 10.48],\n","     'Longitude': [-58.66, -47.91, -70.66, -74.08, -66.86]})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P4X0Av3sxOGr"},"outputs":[],"source":["gdf = gpd.GeoDataFrame(\n","    df, geometry = gpd.points_from_xy(df.Longitude, df.Latitude))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NT9qGckrxcwZ"},"outputs":[],"source":["print(gdf.head())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Slj0GNADxhme"},"outputs":[],"source":["world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n","\n","# We restrict to South America.\n","ax = world[world.continent == 'South America'].plot(\n","    color='white', edgecolor='black')\n","\n","# We can now plot our ``GeoDataFrame``.\n","gdf.plot(ax=ax, color='red')\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"duyeNQN9mYJR"},"source":["### TODO: 14.11.2022\n","1. Include file upload feature [Done]\n","2. Include WordCloud (Nouns, Adjectives, Adverbs) [Done]\n","3. Redesign to include wrap up in a class [Done]\n","\n","#### Reading the xml file"]},{"cell_type":"markdown","metadata":{"id":"nJoqzqc6qVeH"},"source":["# Display Annotations"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4NO5_xrUnrnd"},"outputs":[],"source":["import os\n","import json\n","import pandas as pd"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KuJxiuWAtDn_"},"outputs":[],"source":["with open('data/simple_test1_annotations.json') as json_data:\n","    data = json.load(json_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G6jW8d8qZuXV"},"outputs":[],"source":["for example in data['examples']:\n","  print(example['content'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UCJqzX64aGtv"},"outputs":[],"source":["data.keys()\n","# pd.DataFrame(data['examples'][0]['annotations'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EadF_EeatDZo"},"outputs":[],"source":["pd.DataFrame(data['schema']['tags'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EdS8klrsaxc7"},"outputs":[],"source":["example_0 = data['examples'][0]\n","print(example_0['content'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8JbUTQZQbvSr"},"outputs":[],"source":["all_annotations = {}\n","for i in range(4):\n","  example = data['examples'][i]\n","  # print(example['content'])\n","  for annotation in example['annotations']:\n","    # print(annotation['value'], annotation['tag'], annotation['start'], annotation['end'], annotation['tagged_token_id'])\n","    all_annotations[annotation['tagged_token_id']] = annotation['value'] \n","    # print(annotation['tagged_token_id'], annotation['value'], annotation['tag'], annotation['start'], annotation['end'])\n","all_annotations"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2P7lNsojA-z7"},"outputs":[],"source":["# pd.DataFrame(data['relations'])\n","for relation in data['relations']:\n","  if relation['tagged_token_id'] != None:\n","    # print(relation['tagged_token_id'])\n","    print(f\"{relation['id']}\\t{all_annotations[relation['tagged_token_id']]:20}\\t\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4qCpe8NpDOMJ"},"outputs":[],"source":["all_relations={}\n","for relation in data['relations']:\n","  all_relations[relation['id']] = {'relation_type':relation['pseudo_node_type'],\n","                                   'parent_id':relation['parent_id'],\n","                                   'children':relation['children'],\n","                                   'tagged_token_id':relation['tagged_token_id'],\n","                                   'materialized_path':relation['materialized_path']}\n","  print(relation['id'], all_relations[relation['id']])\n","\n","for relation_id, value in all_relations.items():\n","  if value['relation_type'] != None:\n","    parent =  all_annotations[all_relations[value['parent_id']]['tagged_token_id']]\n","    children_ids =  value['children']\n","    print(f\"From\\n- {parent}\\nTo\")\n","    if children_ids:\n","      for id in children_ids:\n","        print('-',all_annotations[all_relations[id]['tagged_token_id']])\n","    print('='*10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5wTvRK-F62wR"},"outputs":[],"source":["html_text = \"\"\"\n","<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"ee0deb35d002499ea0584c7aad5b8096-0\" class=\"displacy\" width=\"750\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Penrith</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PL-NAME</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">Pooley Bridge</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">PL-NAME</tspan>\n","</text>\n","\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">Eamont</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">PL-NAME</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">Ulleswater</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">PL-NAME</tspan>\n","</text>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-ee0deb35d002499ea0584c7aad5b8096-0-0\" stroke-width=\"2px\" d=\"M70,180.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-ee0deb35d002499ea0584c7aad5b8096-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">from</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n","</g>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-ee0deb35d002499ea0584c7aad5b8096-0-1\" stroke-width=\"2px\" d=\"M420,177.0 C420,89.5 570.0,89.5 570.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-ee0deb35d002499ea0584c7aad5b8096-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">to</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M420,179.0 L412,167.0 428,167.0\" fill=\"currentColor\"/>\n","</g>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-ee0deb35d002499ea0584c7aad5b8096-0-2\" stroke-width=\"2px\" d=\"M245,177.0 C245,2.0 575.0,2.0 575.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-ee0deb35d002499ea0584c7aad5b8096-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">to</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M575.0,179.0 L583.0,167.0 567.0,167.0\" fill=\"currentColor\"/>\n","</g>\n","</svg>\n","\"\"\"\n","IPython.display.HTML(html_text)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K2AIEQEyBQ_e"},"outputs":[],"source":["pd.DataFrame(data['relations'])"]},{"cell_type":"markdown","metadata":{"id":"jiPVYyl6GYT9"},"source":["# Convert XML to TXT"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yurvk5KVGXn9"},"outputs":[],"source":["import xml.etree.ElementTree as ET\n","# Anon1857_b.xml\n","def xml2txt(fpath):\n","  tree = ET.parse(fpath)\n","  root = tree.getroot()\n","  text=''\n","  for chap in root.findall('chap'):\n","    for c in chap:\n","      # if c.text: text+=f'\\n{c.text.strip()}'\n","      if c.tag == 'poem':\n","        for l in c.findall('line'):\n","          if l.text: text+=f'\\n{l.text.strip()}'\n","      if c.tag in 'pi':\n","        print(c.text)\n","  # with open(fpath[:-3]+'txt', 'w', encoding='utf8') as txtfile:\n","  #   txtfile.write(text)\n","  #   return f\"{fpath[:-3]+'txt'} successfully created!\"\n","    # return text\n","  # return f\"Error creating {fpath[:-3]+'txt'}!\"\n","xml2txt('data/Anon1857_b.xml')"]},{"cell_type":"code","source":["from xml.etree import ElementTree as ET\n"," \n","tree = ET.parse('data/Anon1857_b.xml')\n","s, d = \"'\", \"\\\"\"\n","json_text = '[\\n' #print('[')\n","for i, p in enumerate(tree.findall(\".//p\")):\n","    # Get all inner text\n","    json_text += '  {\\n' #print('  {')\n","    json_text += f'    \"para_id\": \"{i}\",\\n' #print(f'    \"para_id\": \"{i}\",')\n","    text = \" \".join(t.strip() for t in p.itertext())\n","    json_text += f'    \"text\": \"{text.replace(d,s)}\"\\n' #print(f'    \"text\": \"{text.replace(d,s)}\"')\n","    json_text +='  },\\n' # print('  },')\n","json_text += ']' # print(']')\n","\n","with open('data/the_english_lakes_anon1857b.json', 'w', encoding='utf8') as jsonfile:\n","  jsonfile.write(json_text)"],"metadata":{"id":"X-fHHYtG7H-Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import xml.etree.ElementTree as ET\n","\n","tree = ET.parse('data/Anon1857_b.xml')\n","text = str(f\"{ET.tostring(tree.getroot(), encoding='utf-8', method='text')}\")\n","\n","print(text.replace('\\n', ''))"],"metadata":{"id":"dtN-v7Hal26A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["type(text)"],"metadata":{"id":"EuPtjyvanqnn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["nlp = spacy.load('en_core_web_sm')"],"metadata":{"id":"yrt8bPuZdN_Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# nlp = spacy.load(\"en_core_web_sm\")\n","# doc = nlp(\"Autonomous cars shift insurance liability toward manufacturers\")\n","# for token in doc:\n","#     print(token.text, token.dep_, token.head.text, token.head.pos_,\n","#             [child for child in token.children])\n","for chunk in doc.noun_chunks:\n","    print(chunk.text, chunk.root.text, chunk.root.dep_,\n","            chunk.root.head.text)"],"metadata":{"id":"RnfoBvNGK1G7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# nlp = spacy.load(\"en_core_web_sm\")\n","doc = nlp(\"Penrith is a beautiful town with two roads leading to Pooley Bridge, about six miles distant, which spans the Eamont just at its issue from Ulleswater.\")\n","displacy.render(doc, style='dep', jupyter=True, options={'distance': 90})"],"metadata":{"id":"kgtpUtqlMMGq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for chunk in doc.noun_chunks:\n","    print(chunk.text, chunk.root.text, chunk.root.dep_,\n","            chunk.root.head.text)"],"metadata":{"id":"zTDCaqPjOxji"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tsyuWFgzbjAV"},"source":["# Sense-of-plase (WordCloud)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X0dDgVdMgc4W"},"outputs":[],"source":["files = [f\"data/example_texts/{f}\" for f in os.listdir('data/example_texts') if f.endswith('.txt')]\n","\n","def get_cloud(plname, tag, files, window=20):\n","  plname_sop = []\n","  for f in files:\n","    doc = nlp(open(f, 'r', encoding='utf8').read())\n","    for i in range(len(doc)):\n","      if doc[i].text ==plname:\n","        for j in range(i-(int(window/2)),i+int(window/2)):\n","          if doc[j].pos_ == tag:\n","            plname_sop.append(doc[j].text)\n","  return plname_sop"]},{"cell_type":"code","source":["doc1 = nlp(\"This is a sentence.\")\n","doc2 = nlp(\"This is another sentence.\")\n","html = displacy.render([doc1, doc2], style=\"dep\", page=True)\n","html"],"metadata":{"id":"p17LK0DjQ3Ch"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# plname_sop = get_cloud('Keswick', 'VERB', files)\n","print(Counter(plname_sop).most_common(20))\n","wordcloud = WordCloud(width = 800, height = 800,\n","        background_color ='white',\n","        min_font_size = 10).generate(' '.join(plname_sop))\n","\n","# plot the WordCloud image\t\t\t\t\t\n","plt.figure(figsize = (7, 7), facecolor = None)\n","plt.imshow(wordcloud)\n","plt.axis(\"off\")\n","plt.tight_layout(pad = 0)"],"metadata":{"id":"rJSOG5N7hPB2"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WsJT8qFYg-Mq"},"outputs":[],"source":["def get_cloud(plname, tag, window=20):\n","  plname_sop = []\n","  for i in range(len(doc)):\n","    if doc[i].text ==plname:\n","      for j in range(i-(int(window/2)),i+int(window/2)):\n","        if doc[j].pos_ == tag:\n","          plname_sop.append(doc[j].text)\n","  return plname_sop"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nrljLRBLDuSp"},"outputs":[],"source":["# plname_sop = get_cloud('Penrith', 'ADJ')\n","plname_sop = get_cloud('Keswick', 'ADJ')\n","\n","# plname_sop = get_cloud('Penrith', 'ADV')\n","# plname_sop = get_cloud('Keswick', 'ADV')\n","\n","# plname_sop = get_cloud('Penrith', 'NOUN')\n","# plname_sop = get_cloud('Keswick', 'NOUN')\n","\n","wordcloud = WordCloud(width = 800, height = 800,\n","        background_color ='white',\n","        min_font_size = 10).generate(' '.join(plname_sop))\n","\n","# plot the WordCloud image\t\t\t\t\t\n","plt.figure(figsize = (7, 7), facecolor = None)\n","plt.imshow(wordcloud)\n","plt.axis(\"off\")\n","plt.tight_layout(pad = 0)\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"7TuAqwvp2YrU"},"source":["#### Other code"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EEcE8zsh7GGX"},"outputs":[],"source":["spacy_entities = extract_entities_with_spacy(doc)\n","\n","IPython.display.HTML(\n","    generate_html(get_token_tags(text, spacy_entities)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1G8fzHtSp6dw"},"outputs":[],"source":["# We exclude the following components as we do not need them. \n","nlp = spacy.load('en_core_web_sm') #, exclude=['parser', 'ner'])\n","\n","# Load the English PyMUSAS rule based tagger in a separate spaCy pipeline\n","english_tagger_pipeline = spacy.load('en_dual_none_contextual')\n","\n","# Adds the English PyMUSAS rule based tagger to the main spaCy pipeline\n","nlp.add_pipe('pymusas_rule_based_tagger', source=english_tagger_pipeline)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hRyInolaQLLc"},"outputs":[],"source":["extractor = Extractor(EXAMPLE_TEXT, entity_tag_list)\n","# extractor.visualize(extractor.sem_entities)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GdiGMVxb9rlZ"},"outputs":[],"source":["import pandas as pd\n","# Load the LD80 corpus\n","LDv5_corpus_pl_names_workbook = pd.ExcelFile('data/LDv5_corpus_pl_names.xlsx')\n","LD_corpus_pl_names_df = pd.read_excel(LDv5_corpus_pl_names_workbook, sheet_name='LDv5_corpus_pl_names')\n","\n","# Extract names from 'pl_name' column\n","pl_names = set([name.title() for name in LD_corpus_pl_names_df['pl_name']])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vcYyZxGUOeKs"},"outputs":[],"source":["import os\n","import re\n","import spacy\n","import en_core_web_sm\n","# import streamlit as st\n","import pandas as pd\n","import collections\n","from collections import Counter\n","from lemminflect import getLemma, getInflection\n","\n","EXAMPLES_DIR = 'code/data/example_texts'\n","example_files = sorted([f for f in os.listdir(EXAMPLES_DIR)]) # if f.startswith('Reviews')])\n","\n","BG_COLOR = {'GPE':'#feca74', 'CARDINAL':'#e4e7d2', 'FAC':'#9cc9cc',\n","            'QUANTITY':'#e4e7d2', 'PERSON':'#aa9cfc', 'ORDINAL':'#e4e7d2', \n","            'ORG':'#7aecec', 'PL-NAME':'#feca74', 'no_tag':'#FFFFFF',\n","            'GEO-FEATURE': '#9cc9cc', 'NORP':'#d9fe74', 'LOC':'#9ac9f5',\n","            'DATE':'#c7f5a9', 'PRODUCT':'#edf5a9', 'EVENT': '#e1a9f5',\n","            'TIME':'#a9f5bc', 'WORK_OF_ART':'#e6c1d7', 'LAW':'#e6e6c1',\n","            'LANGUAGE':'#c9bdc7', 'PERCENT':'#c9ebf5', 'MONEY':'#b3d6f2',\n","            'EMOTION':'#f2ecd0', 'TIME-sem':'#d0e0f2', 'MOVEMENT':'#f2d0d0'\n","}\n","\n","# `PERSON` People, including fictional.\t*Fred Flintstone*\n","# `NORP`\tNationalities or religious or political groups.\t*The Republican Party*\n","# `FAC`\tBuildings, airports, highways, bridges, etc.\t*Logan International Airport, The Golden Gate*\n","# `ORG`\tCompanies, agencies, institutions, etc.\t*Microsoft, FBI, MIT*\n","# `GPE`\tCountries, cities, states.\t*France, UAR, Chicago, Idaho*\n","# `LOC`\tNon-GPE locations, mountain ranges, bodies of water.\t*Europe, Nile River, Midwest*\n","# `DATE`\tAbsolute or relative dates or periods.\t*20 July 1969*\n","# `CARDINAL`\n","# `QUANTITY` Measurements, as of weight or distance.\t*Several kilometers, 55kg*\n","# `ORDINAL`\t\"first\", \"second\", etc.\t*9th, Ninth*\n","# `PRODUCT`\tObjects, vehicles, foods, etc. (Not services.)\t*Formula 1*\n","# `EVENT`\tNamed hurricanes, battles, wars, sports events, etc.\t*Olympic Games*\n","# `TIME`\tTimes smaller than a day.\t*Four hours*\n","# `LAW`\tNamed documents made into laws.\t*Roe v. Wade*\n","# `LANGUAGE`\tAny named language.\t*English*\n","# `PERCENT`\tPercentage, including \"%\".\t*Eighty percent*\n","# `MONEY`\tMonetary values, including unit. *Twenty Cents*\n","\n","place_names = open('code/data/placenames.txt').readlines()\n","geof_names  = open('code/data/geo_feature_nouns.txt').readlines()\n","# locative_adverbs = open() # complete later\n","\n","nlp = spacy.load('en_core_web_sm')\n","\n","# Load the English PyMUSAS rule based tagger in a separate spaCy pipeline\n","english_tagger_pipeline = spacy.load('en_dual_none_contextual')\n","\n","# Adds the English PyMUSAS rule based tagger to the main spaCy pipeline\n","nlp.add_pipe('pymusas_rule_based_tagger', source=english_tagger_pipeline)\n","\n","# Pass the example text through the pipeline for proper tokenisation\n","\n","# show text unformated text\n","def show_plain_text(txtstr):\n","  'Original text:'\n","  start_mark = f'<mark class=\"entity\" style=\"background: #FFFFFF; line-height: 2; border-radius: 0.35em;\">'\n","  end_mark = '\\n</mark>'\n","  return f\"{start_mark}{txtstr}{end_mark}\"\n","\n","    # extract all entities with semtagger\n","    def extract_entities_with_semtagger(tokens, index_list, tag):\n","      entityPosLen={}\n","      for i in index_list:\n","        start_char = 1+len(\" \".join(tokens[:i]))\n","        entityPosLen[start_char] = (len(tokens[i]), tokens[i], tag)\n","      return entityPosLen\n","\n","    \n","    # Get the index list of a sem tag\n","    def get_sem_tagged(tag_type):\n","      index_list = []\n","      for i in range(len(output_doc)):\n","        if output_doc[i]._.pymusas_tags[0].startswith(tag_type[0]):\n","           index_list.append(i)\n","      return index_list  \n","      \n","    #Regex----------------------------------------------------------------\n","    sorted_pl_names = [name.strip() for name in sorted(place_names, key=lambda x: len(x), reverse=True)]\n","    #extract place name entities/mentions\n","    pl_names_ents = extract_entities_with_regex(processed_text, sorted_pl_names)\n","\n","    #extract geo feature entities/mentions\n","    gf_names_ents = extract_entities_with_regex(processed_text, get_inflections(geof_names), tag='GEO-FEATURE')\n","\n","    # Merge all extracted fearture names and mentions\n","    regex_entities = {**pl_names_ents, **gf_names_ents}\n","    regex_entities = collections.OrderedDict(sorted(regex_entities.items()))\n","\n","    #Spacy-----------------------------------------------------------------\n","    doc = nlp(processed_text)\n","    spacy_entities = extract_entities_with_spacy(doc)\n","\n","    #Regex+Spacy-----------------------------------------------------------\n","    regex_spacy_entities = regex_entities.copy()\n","    banned_start_points=[]\n","    for start, (length, e, t) in regex_spacy_entities.items():\n","      banned_start_points.extend(list(range(start, start+length-1)))\n","\n","    for start, (l, e, t) in spacy_entities.items():\n","      if start not in banned_start_points:\n","        if t in ['GPE','ORG', 'LOC', 'FAC', 'PERSON']:\n","          regex_spacy_entities[start] = (l, e, 'PL-NAME')\n","        else:\n","          regex_spacy_entities[start] = (l, e, t)\n","    regex_spacy_entities = collections.OrderedDict(sorted(regex_spacy_entities.items()))\n","\n","    #Sem Tagger-----------------------------------------------------------\n","    sem_tag_types = ['EMOTION', 'MOVEMENT', 'TIME-sem']\n","    semtagger_entities={}\n","    for tag_type in sem_tag_types:\n","      tag_entities = extract_entities_with_semtagger(text_tokens, get_sem_tagged(tag_type),tag_type) \n","      semtagger_entities = {**semtagger_entities, **tag_entities}\n","    semtagger_entities = collections.OrderedDict(sorted(semtagger_entities.items()))\n","\n","    #Regex Spacy and Sem Tagger-------------------------------------------\n","    regex_spacy_sem_entities = regex_spacy_entities.copy()\n","    # Do not overwrite regex entities\n","    banned_start_points=[]\n","    for start, (length, e, t) in regex_spacy_sem_entities.items():\n","      banned_start_points.extend(list(range(start, start+length-1)))\n","\n","    # Add only entities not captured by regex\n","    for start, (l, e, t) in semtagger_entities.items():\n","      if start not in banned_start_points:\n","          regex_spacy_sem_entities[start] = (l, e, t)\n","    regex_spacy_sem_entities = collections.OrderedDict(sorted(regex_spacy_sem_entities.items()))\n","\n","    t_dict = {\n","    '⛱ Regex Extractor': (\"**⛱ Regex Extraction**\", regex_entities),\n","    '🏓 Spacy Extractor': (\"**🏓 Spacy Extraction**\", spacy_entities),\n","    '🛸 Sem_Tag Extractor': (\"**🛸 Semantic Tagging [`EMOTION`, `MOVEMENT`, `TIME-sem`]**\", semtagger_entities),\n","    '📌 Regex_Spacy Extractor': (\"**📌 Regex_Spacy Extraction**\", regex_spacy_entities),\n","    '🏆 Regex_Spacy_Semtag Extractor': (\"**📌 Regex_Spacy_Semtag Extraction**\", regex_spacy_sem_entities)\n","    }\n","    \n","    return t_dict, processed_text\n","    \n","#📃📌📈📈📉⛱🏓🏆🎲 \n","# ⛱🏓📌🛸🎲♟ 💡🖱️\n"]}],"metadata":{"colab":{"collapsed_sections":["VQzZg_4jQ9Ch","LCQBR8lJTAii","jOdjjJwFHv11","vb8f7aoPsYgL","Zw9jVk97R4SB","1tCywxkPi1r2","WwolMngoq_hs"],"provenance":[{"file_id":"1a8NMWYvBRyttBo0jGMw4zc0NFdV17Ycx","timestamp":1674427171198},{"file_id":"https://github.com/IgnatiusEzeani/spatial_narrative_project/blob/main/code/python_script.ipynb","timestamp":1665988104835}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":0}